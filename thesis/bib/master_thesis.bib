@InProceedings{Nair2010,
  author    = {Vinod Nair and Geoffrey E. Hinton},
  booktitle = {ICML},
  title     = {Rectified Linear Units Improve Restricted Boltzmann Machines},
  year      = {2010},
  pages     = {807-814},
  cdate     = {1262304000000},
  comment   = {Paper presenting the ReLU activation function},
  url       = {https://icml.cc/Conferences/2010/papers/432.pdf},
}

@Article{Palerme2021,
  author    = {Cyril Palerme and Malte Müller},
  title     = {Calibration of sea ice drift forecasts using random forest algorithms},
  year      = {2021},
  month     = {aug},
  number    = {8},
  pages     = {3989--4004},
  volume    = {15},
  doi       = {10.5194/tc-15-3989-2021},
  file      = {:palerme2021.pdf:PDF},
  publisher = {Copernicus {GmbH}},
}

@Article{Fritzner2020,
  author    = {Sindre Fritzner and Rune Graversen and Kai H. Christensen},
  title     = {Assessment of High-Resolution Dynamical and Machine Learning Models for Prediction of Sea Ice Concentration in a Regional Application},
  year      = {2020},
  month     = oct,
  note      = {Neural Networks for predicting Sea-Ice concentration are only slightly more accurate than persistence forecasting for short-term predictions.},
  number    = {11},
  volume    = {125},
  comment   = {*Read*},
  doi       = {10.1029/2020jc016277},
  file      = {:fritzner2020.pdf:PDF},
  publisher = {American Geophysical Union ({AGU})},
}

@Article{Soenderby2020,
  author        = {Casper Kaae Sønderby and Lasse Espeholt and Jonathan Heek and Mostafa Dehghani and Avital Oliver and Tim Salimans and Shreya Agrawal and Jason Hickey and Nal Kalchbrenner},
  title         = {MetNet: A Neural Weather Model for Precipitation Forecasting},
  year          = {2020},
  month         = mar,
  abstract      = {Weather forecasting is a long standing scientific challenge with direct social and economic impact. The task is suitable for deep neural networks due to vast amounts of continuously collected data and a rich spatial and temporal structure that presents long range dependencies. We introduce MetNet, a neural network that forecasts precipitation up to 8 hours into the future at the high spatial resolution of 1 km$^2$ and at the temporal resolution of 2 minutes with a latency in the order of seconds. MetNet takes as input radar and satellite data and forecast lead time and produces a probabilistic precipitation map. The architecture uses axial self-attention to aggregate the global context from a large input patch corresponding to a million square kilometers. We evaluate the performance of MetNet at various precipitation thresholds and find that MetNet outperforms Numerical Weather Prediction at forecasts of up to 7 to 8 hours on the scale of the continental United States.},
  archiveprefix = {arXiv},
  eprint        = {2003.12140},
  file          = {:http\://arxiv.org/pdf/2003.12140v2:PDF},
  keywords      = {cs.LG, physics.ao-ph, stat.ML},
  primaryclass  = {cs.LG},
}

@Article{Agrawal2019,
  author        = {Shreya Agrawal and Luke Barrington and Carla Bromberg and John Burge and Cenk Gazen and Jason Hickey},
  title         = {Machine Learning for Precipitation Nowcasting from Radar Images},
  year          = {2019},
  month         = dec,
  abstract      = {High-resolution nowcasting is an essential tool needed for effective adaptation to climate change, particularly for extreme weather. As Deep Learning (DL) techniques have shown dramatic promise in many domains, including the geosciences, we present an application of DL to the problem of precipitation nowcasting, i.e., high-resolution (1 km x 1 km) short-term (1 hour) predictions of precipitation. We treat forecasting as an image-to-image translation problem and leverage the power of the ubiquitous UNET convolutional neural network. We find this performs favorably when compared to three commonly used models: optical flow, persistence and NOAA's numerical one-hour HRRR nowcasting prediction.},
  archiveprefix = {arXiv},
  eprint        = {1912.12132},
  file          = {:http\://arxiv.org/pdf/1912.12132v1:PDF},
  keywords      = {cs.CV, cs.LG, stat.ML},
  primaryclass  = {cs.CV},
}

@Article{Ravuri2021,
  author    = {Suman Ravuri and Karel Lenc and Matthew Willson and Dmitry Kangin and Remi Lam and Piotr Mirowski and Megan Fitzsimons and Maria Athanassiadou and Sheleem Kashem and Sam Madge and Rachel Prudden and Amol Mandhane and Aidan Clark and Andrew Brock and Karen Simonyan and Raia Hadsell and Niall Robinson and Ellen Clancy and Alberto Arribas and Shakir Mohamed},
  journal   = {Nature},
  title     = {Skilful precipitation nowcasting using deep generative models of radar},
  year      = {2021},
  month     = {sep},
  number    = {7878},
  pages     = {672--677},
  volume    = {597},
  doi       = {10.1038/s41586-021-03854-z},
  file      = {:ravuri2021.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Schultz2021,
  author    = {M. G. Schultz and C. Betancourt and B. Gong and F. Kleinert and M. Langguth and L. H. Leufen and A. Mozaffari and S. Stadtler},
  journal   = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  title     = {Can deep learning beat numerical weather prediction?},
  year      = {2021},
  month     = {feb},
  number    = {2194},
  pages     = {20200097},
  volume    = {379},
  comment   = {*READ*

Section 4 covers a lot of interesting problems surrounding meteorological data, and supplies papers which discusses these "shortcomings" in a ML context. Great paper to use for finding articles which discusses individual problems in-depth

Section 5 touch upon data preparation and model evaluation, especially data splitting with regards to auto-correlation. Also, sources discussing more suitable verification metrics than MSE due to the spatio-temporal correlation of meteorological data are referred to.},
  doi       = {10.1098/rsta.2020.0097},
  file      = {:schultz2021.pdf:PDF},
  publisher = {The Royal Society},
}

@Article{Espeholt2021,
  author        = {Lasse Espeholt and Shreya Agrawal and Casper Sønderby and Manoj Kumar and Jonathan Heek and Carla Bromberg and Cenk Gazen and Jason Hickey and Aaron Bell and Nal Kalchbrenner},
  title         = {Skillful Twelve Hour Precipitation Forecasts using Large Context Neural Networks},
  year          = {2021},
  month         = nov,
  note          = {Met-Net 2},
  abstract      = {The problem of forecasting weather has been scientifically studied for centuries due to its high impact on human lives, transportation, food production and energy management, among others. Current operational forecasting models are based on physics and use supercomputers to simulate the atmosphere to make forecasts hours and days in advance. Better physics-based forecasts require improvements in the models themselves, which can be a substantial scientific challenge, as well as improvements in the underlying resolution, which can be computationally prohibitive. An emerging class of weather models based on neural networks represents a paradigm shift in weather forecasting: the models learn the required transformations from data instead of relying on hand-coded physics and are computationally efficient. For neural models, however, each additional hour of lead time poses a substantial challenge as it requires capturing ever larger spatial contexts and increases the uncertainty of the prediction. In this work, we present a neural network that is capable of large-scale precipitation forecasting up to twelve hours ahead and, starting from the same atmospheric state, the model achieves greater skill than the state-of-the-art physics-based models HRRR and HREF that currently operate in the Continental United States. Interpretability analyses reinforce the observation that the model learns to emulate advanced physics principles. These results represent a substantial step towards establishing a new paradigm of efficient forecasting with neural networks.},
  archiveprefix = {arXiv},
  eprint        = {2111.07470},
  file          = {:http\://arxiv.org/pdf/2111.07470v1:PDF;:espeholt2021.pdf:PDF},
  keywords      = {cs.LG, physics.ao-ph},
  primaryclass  = {cs.LG},
}

@Article{Chantry2021,
  author    = {Matthew Chantry and Hannah Christensen and Peter Dueben and Tim Palmer},
  journal   = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  title     = {Opportunities and challenges for machine learning in weather and climate modelling: hard, medium and soft {AI}},
  year      = {2021},
  month     = {feb},
  number    = {2194},
  pages     = {20200083},
  volume    = {379},
  doi       = {10.1098/rsta.2020.0083},
  file      = {:chantry2021.pdf:PDF},
  publisher = {The Royal Society},
}

@Article{Andersson2021,
  author    = {Tom R. Andersson and J. Scott Hosking and Mar{\'{\i}}a P{\'{e}}rez-Ortiz and Brooks Paige and Andrew Elliott and Chris Russell and Stephen Law and Daniel C. Jones and Jeremy Wilkinson and Tony Phillips and James Byrne and Steffen Tietsche and Beena Balan Sarojini and Eduardo Blanchard-Wrigglesworth and Yevgeny Aksenov and Rod Downie and Emily Shuckburgh},
  journal   = {Nature Communications},
  title     = {Seasonal Arctic sea ice forecasting with probabilistic deep learning},
  year      = {2021},
  month     = {aug},
  number    = {1},
  volume    = {12},
  comment   = {Unet for seasonal prediction},
  doi       = {10.1038/s41467-021-25257-4},
  file      = {:Andersson2021.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Zhu2017,
  author    = {Xiao Xiang Zhu and Devis Tuia and Lichao Mou and Gui-Song Xia and Liangpei Zhang and Feng Xu and Friedrich Fraundorfer},
  journal   = {{IEEE} Geoscience and Remote Sensing Magazine},
  title     = {Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources},
  year      = {2017},
  month     = {dec},
  number    = {4},
  pages     = {8--36},
  volume    = {5},
  comment   = {CNN implementation for recognizing spatial features in satellite images},
  doi       = {10.1109/mgrs.2017.2762307},
  file      = {:Zhu2017.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Shi2015,
  author        = {Xingjian Shi and Zhourong Chen and Hao Wang and Dit-Yan Yeung and Wai-kin Wong and Wang-chun Woo},
  title         = {Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting},
  year          = {2015},
  month         = jun,
  abstract      = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.},
  archiveprefix = {arXiv},
  eprint        = {1506.04214},
  file          = {:http\://arxiv.org/pdf/1506.04214v2:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Article{Wandel2020,
  author        = {Nils Wandel and Michael Weinmann and Reinhard Klein},
  title         = {Learning Incompressible Fluid Dynamics from Scratch -- Towards Fast, Differentiable Fluid Models that Generalize},
  year          = {2020},
  month         = jun,
  abstract      = {Fast and stable fluid simulations are an essential prerequisite for applications ranging from computer-generated imagery to computer-aided design in research and development. However, solving the partial differential equations of incompressible fluids is a challenging task and traditional numerical approximation schemes come at high computational costs. Recent deep learning based approaches promise vast speed-ups but do not generalize to new fluid domains, require fluid simulation data for training, or rely on complex pipelines that outsource major parts of the fluid simulation to traditional methods. In this work, we propose a novel physics-constrained training approach that generalizes to new fluid domains, requires no fluid simulation data, and allows convolutional neural networks to map a fluid state from time-point t to a subsequent state at time t + dt in a single forward pass. This simplifies the pipeline to train and evaluate neural fluid models. After training, the framework yields models that are capable of fast fluid simulations and can handle various fluid phenomena including the Magnus effect and Karman vortex streets. We present an interactive real-time demo to show the speed and generalization capabilities of our trained models. Moreover, the trained neural networks are efficient differentiable fluid solvers as they offer a differentiable update step to advance the fluid simulation in time. We exploit this fact in a proof-of-concept optimal control experiment. Our models significantly outperform a recent differentiable fluid solver in terms of computational speed and accuracy.},
  archiveprefix = {arXiv},
  comment       = {Unsupervised learning scheme, maybe CNN, to solve Navier Stokes equations, simulating incompressible fluid motion.},
  eprint        = {2006.08762},
  file          = {:http\://arxiv.org/pdf/2006.08762v3:PDF},
  keywords      = {cs.LG, stat.ML},
  primaryclass  = {cs.LG},
}

@Article{Cirstea2018,
  author        = {Razvan-Gabriel Cirstea and Darius-Valer Micu and Gabriel-Marcel Muresan and Chenjuan Guo and Bin Yang},
  title         = {Correlated Time Series Forecasting using Deep Neural Networks: A Summary of Results},
  year          = {2018},
  month         = aug,
  abstract      = {Cyber-physical systems often consist of entities that interact with each other over time. Meanwhile, as part of the continued digitization of industrial processes, various sensor technologies are deployed that enable us to record time-varying attributes (a.k.a., time series) of such entities, thus producing correlated time series. To enable accurate forecasting on such correlated time series, this paper proposes two models that combine convolutional neural networks (CNNs) and recurrent neural networks (RNNs). The first model employs a CNN on each individual time series, combines the convoluted features, and then applies an RNN on top of the convoluted features in the end to enable forecasting. The second model adds additional auto-encoders into the individual CNNs, making the second model a multi-task learning model, which provides accurate and robust forecasting. Experiments on two real-world correlated time series data set suggest that the proposed two models are effective and outperform baselines in most settings. This report extends the paper "Correlated Time Series Forecasting using Multi-Task Deep Neural Networks," to appear in ACM CIKM 2018, by providing additional experimental results.},
  archiveprefix = {arXiv},
  comment       = {Applying deep learning to highly spatially -and temporally correlated data, such as meterological data. Though the paper itself is general, i.e. not applied to met-data.},
  eprint        = {1808.09794},
  file          = {:http\://arxiv.org/pdf/1808.09794v2:PDF;:Cirstea2018.pdf:PDF},
  keywords      = {cs.LG, stat.ML},
  primaryclass  = {cs.LG},
}

@Book{Maraun_2017,
  author    = {Douglas Maraun and Martin Widmann},
  publisher = {Cambridge University Press},
  title     = {Statistical Downscaling and Bias Correction for Climate Research},
  year      = {2017},
  address   = {Cambridge},
  isbn      = {9781107588783},
  month     = {dec},
  doi       = {10.1017/9781107588783},
  file      = {:Maraun2017.pdf:PDF},
}

@Misc{MOI2021,
  author    = {{Mercator Ocean International}},
  title     = {Arctic Ocean - High resolution Sea Ice Concentration and Sea Ice Type},
  year      = {2021},
  doi       = {10.48670/MOI-00122},
  file      = {:Dinessen2021.pdf:PDF},
  keywords  = {oceanography},
  language  = {en},
  publisher = {Mercator Ocean International},
}

@Misc{MOI2015,
  author    = {Frode Dinessen and Bruce Hackett and Matilde Brandt Kreiner},
  title     = {Arctic Ocean - Sea Ice Concentration Charts - Svalbard and Greenland},
  year      = {2015},
  doi       = {10.48670/MOI-00128},
  file      = {:Dinessen2020.pdf:PDF},
  keywords  = {oceanography},
  language  = {en},
  publisher = {Mercator Ocean International},
}

@Article{Ronneberger2015,
  author        = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  year          = {2015},
  month         = may,
  abstract      = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  archiveprefix = {arXiv},
  eprint        = {1505.04597},
  file          = {:http\://arxiv.org/pdf/1505.04597v1:PDF;:Ronneberger2015.pdf:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Misc{JETSI2014,
  author    = {{JCOMM Expert Team on Sea Ice}},
  title     = {Sea-Ice Nomenclature: snapshot of the WMO Sea Ice Nomenclature WMO No. 259, volume 1 – Terminology and Codes; Volume II – Illustrated Glossary and III – International System of Sea-Ice Symbols) .},
  year      = {2014},
  doi       = {10.25607/OBP-1515},
  file      = {:Sea_Ice_Nomenclature_March_2014.pdf:PDF},
  publisher = {WMO-JCOMM},
}

@Article{Melsom2019,
  author    = {Arne Melsom and Cyril Palerme and Malte Müller},
  journal   = {Ocean Science},
  title     = {Validation metrics for ice edge position forecasts},
  year      = {2019},
  month     = {may},
  number    = {3},
  pages     = {615--630},
  volume    = {15},
  comment   = {paper presenting Batch Norm technique for standardized gradient flow during backpropagation},
  doi       = {10.5194/os-15-615-2019},
  file      = {Validation metrics for ice edge position forecasts:Melsom2019.pdf:PDF},
  publisher = {Copernicus {GmbH}},
}

@Article{Goessling2016,
  author    = {H. F. Goessling and S. Tietsche and J. J. Day and E. Hawkins and T. Jung},
  journal   = {Geophysical Research Letters},
  title     = {Predictability of the Arctic sea ice edge},
  year      = {2016},
  month     = {feb},
  number    = {4},
  pages     = {1642--1650},
  volume    = {43},
  doi       = {10.1002/2015gl067232},
  file      = {Article that introduces IIEE:Goessling2016.pdf:PDF},
  publisher = {American Geophysical Union ({AGU})},
}

@Article{Goessling2018,
  author    = {H. F. Goessling and T. Jung},
  journal   = {Quarterly Journal of the Royal Meteorological Society},
  title     = {A probabilistic verification score for contours: Methodology and application to Arctic ice-edge forecasts},
  year      = {2018},
  month     = apr,
  number    = {712},
  pages     = {735--743},
  volume    = {144},
  doi       = {10.1002/qj.3242},
  file      = {Article that introduces SPS:Goessling2018.pdf:PDF},
  publisher = {Wiley},
}

@Article{Micikevicius2017,
  author        = {Paulius Micikevicius and Sharan Narang and Jonah Alben and Gregory Diamos and Erich Elsen and David Garcia and Boris Ginsburg and Michael Houston and Oleksii Kuchaiev and Ganesh Venkatesh and Hao Wu},
  title         = {Mixed Precision Training},
  year          = {2017},
  month         = oct,
  abstract      = {Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units.},
  archiveprefix = {arXiv},
  comment       = {Paper presenting mixed precision training. Mixed precision was considered for use in the thesis during model training, as it decreases the memory needed for a training sample, speed up computations as well as decreases the memory bandwidth. However, mixed precision proved to be more difficult to implement than the docs suggested. With unclear descriptions and guides pointing towards different direction. Thus mixed precision was not pursued further, as the nvidia A100 GPU with 80GB of memory is able to fit a 1km model without decreasing sample size.},
  eprint        = {1710.03740},
  file          = {:http\://arxiv.org/pdf/1710.03740v3:PDF},
  keywords      = {cs.AI, cs.LG, stat.ML},
  primaryclass  = {cs.AI},
}

@Misc{TwoSigma,
  author       = {Two Sigma},
  howpublished = {webpage},
  title        = {A Workaround for Non-Determinism in TensorFlow},
  comment      = {Web-article discussing some workarounds for non-deterministic behaviour resulting from training models on a GPU},
}

@Article{Casati2008,
  author    = {B. Casati and L. J. Wilson and D. B. Stephenson and P. Nurmi and A. Ghelli and M. Pocernich and U. Damrath and E. E. Ebert and B. G. Brown and S. Mason},
  journal   = {Meteorological Applications},
  title     = {Forecast verification: current status and future directions},
  year      = {2008},
  number    = {1},
  pages     = {3--18},
  volume    = {15},
  doi       = {10.1002/met.52},
  publisher = {Wiley},
}

@Article{Dukhovskoy2015,
  author    = {Dmitry S. Dukhovskoy and Jonathan Ubnoske and Edward Blanchard-Wrigglesworth and Hannah R. Hiester and Andrey Proshutinsky},
  journal   = {Journal of Geophysical Research: Oceans},
  title     = {Skill metrics for evaluation and comparison of sea ice models},
  year      = {2015},
  month     = {sep},
  number    = {9},
  pages     = {5910--5931},
  volume    = {120},
  comment   = {Paper introducing the Modified Hausdorff Distance as a ice edge metrics},
  doi       = {10.1002/2015jc010989},
  publisher = {American Geophysical Union ({AGU})},
}

@Misc{IMO2017,
  author       = {International Maritime Organization},
  howpublished = {webpage},
  month        = jan,
  title        = {International Code for Ships Operating in Polar Waters (Polar Code)},
  year         = {2017},
  abstract     = {IMO's International Code for Ships Operating in Polar Waters (Polar Code) is mandatory under both the International Convention for the Safety of Life at Sea (SOLAS) and the International Convention for the Prevention of Pollution from Ships (MARPOL). The Polar Code covers the full range of design, construction, equipment, operational, training, search and rescue and environmental protection matters relevant to ships operating in the inhospitable waters surrounding the two poles. The Polar Code entered into force on 1 January 2017.

The Polar Code and SOLAS amendments were adopted during the 94th session of IMO’s Maritime Safety Committee (MSC), in November 2014; the environmental provisions and MARPOL amendments were adopted during the 68th session of the Marine Environment Protection Committee (MEPC) in May 2015.},
  comment      = {Webpage announcing the Polar Code, which covers the full range of shipping-related matters relevant to navigation in Arctic waters. Not really a soruce, (since the Polar Code is not freely available...), but one standard set, which was mentioned by Cyril, is that ships may be qualified to operate in waters containing a SIC up to 10%.},
  url          = {https://www.imo.org/en/OurWork/Safety/Pages/polar-code.aspx},
}

@Article{Ho2010,
  author    = {Joshua Ho},
  journal   = {Marine Policy},
  title     = {The implications of Arctic sea ice decline on shipping},
  year      = {2010},
  month     = {may},
  number    = {3},
  pages     = {713--715},
  volume    = {34},
  doi       = {10.1016/j.marpol.2009.10.009},
  publisher = {Elsevier {BV}},
}

@Online{reback2020pandas,
  author    = {The pandas development team},
  doi       = {10.5281/zenodo.3509134},
  month     = feb,
  publisher = {Zenodo},
  title     = {pandas-dev/pandas: Pandas},
  url       = {https://doi.org/10.5281/zenodo.3509134},
  version   = {latest},
  year      = {2020},
}

@InProceedings{mckinney-proc-scipy-2010,
  author    = {{W}es {M}c{K}inney},
  booktitle = {{P}roceedings of the 9th {P}ython in {S}cience {C}onference},
  title     = {{D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython},
  year      = {2010},
  editor    = {{S}t\'efan van der {W}alt and {J}arrod {M}illman},
  pages     = {56 - 61},
  doi       = {10.25080/Majora-92bf1922-00a},
}

@Article{Shelhamer2017,
  author    = {Evan Shelhamer and Jonathan Long and Trevor Darrell},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Fully Convolutional Networks for Semantic Segmentation},
  year      = {2017},
  month     = {apr},
  number    = {4},
  pages     = {640--651},
  volume    = {39},
  comment   = {Paper presenting the FCN model for semantic image segmentation},
  doi       = {10.1109/tpami.2016.2572683},
  file      = {:Long2017.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Mueller2017,
  author    = {Malte Müller and Yurii Batrak and J{\o}rn Kristiansen and Morten A. {\O}. K{\o}ltzow and Gunnar Noer and Anton Korosov},
  journal   = {Monthly Weather Review},
  title     = {Characteristics of a Convective-Scale Weather Forecasting System for the European Arctic},
  year      = {2017},
  month     = {dec},
  number    = {12},
  pages     = {4771--4787},
  volume    = {145},
  comment   = {Paper presenting the convective-scale atmospheric prediction system AROME ARCTIC

Section 3.
The Cold Air Outbreak (CAO) phenomena is described. A CAO is an event that occurs during winter, where cold air masses are transported from ice-covered towards lower latitude ice-free areas. As I have understood from discussions with Malte and Cyril, a CAO would cause a movement surge for the Sea Ice to translate towards lower latitudes. Could potentially also cause leads to form in the higher latitude sea ice where the cold air masses are originated and transported away from. However, might be difficult to detect such an event for short timescales, especially with regards to the limited observations available in the arctic. Thus, as Malte suggested, an interesting experiment would be to simulate a CAO using artifically constructed AROME Arctic data, and inspect how the model responds.},
  doi       = {10.1175/mwr-d-17-0194.1},
  file      = {:Muller2017.pdf:PDF},
  publisher = {American Meteorological Society},
}

@Article{Lin2017,
  author        = {Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
  title         = {Focal Loss for Dense Object Detection},
  year          = {2017},
  month         = aug,
  abstract      = {The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.},
  archiveprefix = {arXiv},
  eprint        = {1708.02002},
  file          = {:http\://arxiv.org/pdf/1708.02002v2:PDF;:Lin2018.pdf:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Misc{He2015,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1502.01852},
  file      = {:He2015.pdf:PDF},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@InProceedings{Krizhevsky2012,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  year      = {2012},
  editor    = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  volume    = {25},
  comment   = {Paper presenting the AlexNet CNN},
  url       = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
}

@Article{Wang2017,
  author    = {Lei Wang and K. Scott and David Clausi},
  journal   = {Remote Sensing},
  title     = {Sea Ice Concentration Estimation during Freeze-Up from {SAR} Imagery Using a Convolutional Neural Network},
  year      = {2017},
  month     = {apr},
  number    = {5},
  pages     = {408},
  volume    = {9},
  comment   = {Paper presenting a LandSea mask interpolation technique for should be but can't NaN values covered by a mask.},
  doi       = {10.3390/rs9050408},
  file      = {:Wang2017.pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@Article{Long2014,
  author        = {Jonathan Long and Evan Shelhamer and Trevor Darrell},
  title         = {Fully Convolutional Networks for Semantic Segmentation},
  year          = {2014},
  month         = nov,
  archiveprefix = {arXiv},
  comment       = {Paper presenting the Fully Convolutional Network, (kind of preprocessor to the UNET)},
  eprint        = {1411.4038},
  file          = {:http\://arxiv.org/pdf/1411.4038v2:PDF;:Long2015.pdf:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Article{He2015a,
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title         = {Deep Residual Learning for Image Recognition},
  year          = {2015},
  month         = dec,
  abstract      = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  comment       = {Paper presenting the ResNet architecture},
  eprint        = {1512.03385},
  file          = {:http\://arxiv.org/pdf/1512.03385v1:PDF;:He2015(resnet).pdf:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Article{Batrak2018,
  author    = {Yurii Batrak and Ekaterina Kourzeneva and Mariken Homleid},
  journal   = {Geoscientific Model Development},
  title     = {Implementation of a simple thermodynamic sea ice scheme, {SICE} version 1.0-38h1, within the {ALADIN}{\textendash}{HIRLAM} numerical weather prediction system version 38h1},
  year      = {2018},
  month     = {aug},
  number    = {8},
  pages     = {3347--3368},
  volume    = {11},
  comment   = {Article presenting the snow-on-ice variable present in AROME Arctic from (mid-2018?). The introduction of this variable shifted the T2M bias over sea ice, effectively limiting the dataset which I can use to train my unet,},
  doi       = {10.5194/gmd-11-3347-2018},
  file      = {:Batrak2018.pdf:PDF},
  publisher = {Copernicus {GmbH}},
}

@Article{Spreen2011,
  author    = {Gunnar Spreen and Ron Kwok and Dimitris Menemenlis},
  journal   = {Geophysical Research Letters},
  title     = {Trends in Arctic sea ice drift and role of wind forcing: 1992-2009},
  year      = {2011},
  month     = {oct},
  number    = {19},
  pages     = {n/a--n/a},
  volume    = {38},
  comment   = {Surface winds influence Sea Ice Drift},
  doi       = {10.1029/2011gl048970},
  publisher = {American Geophysical Union ({AGU})},
}

@Article{Yu2020,
  author    = {Xiaoyong Yu and Annette Rinke and Wolfgang Dorn and Gunnar Spreen and Christof Lüpkes and Hiroshi Sumata and Vladimir M. Gryanik},
  journal   = {The Cryosphere},
  title     = {Evaluation of Arctic sea ice drift and its dependency on near-surface wind and sea ice conditions in the coupled regional climate model {HIRHAM}{\textendash}{NAOSIM}},
  year      = {2020},
  month     = {may},
  number    = {5},
  pages     = {1727--1746},
  volume    = {14},
  comment   = {Sea Ice Drift Speed inverse proportional to SIC},
  doi       = {10.5194/tc-14-1727-2020},
  publisher = {Copernicus {GmbH}},
}

@Article{Ioffe2015,
  author        = {Sergey Ioffe and Christian Szegedy},
  title         = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  year          = {2015},
  month         = feb,
  abstract      = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.},
  archiveprefix = {arXiv},
  eprint        = {1502.03167},
  file          = {:http\://arxiv.org/pdf/1502.03167v3:PDF;:Ioffe2015.pdf:PDF},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{Wu2018,
  author        = {Yuxin Wu and Kaiming He},
  title         = {Group Normalization},
  year          = {2018},
  month         = mar,
  abstract      = {Batch Normalization (BN) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- BN's error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits BN's usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization (GN) as a simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization. GN's computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN-based counterparts for object detection and segmentation in COCO, and for video classification in Kinetics, showing that GN can effectively replace the powerful BN in a variety of tasks. GN can be easily implemented by a few lines of code in modern libraries.},
  archiveprefix = {arXiv},
  comment       = {Paper presenting group normalization for standardized gradient flow given small batch sizes},
  eprint        = {1803.08494},
  file          = {:http\://arxiv.org/pdf/1803.08494v3:PDF;:Wu2018.pdf:PDF},
  keywords      = {cs.CV, cs.LG},
  primaryclass  = {cs.CV},
}

@Article{Ludwig2020,
  author    = {Valentin Ludwig and Gunnar Spreen and Leif Toudal Pedersen},
  journal   = {Remote Sensing},
  title     = {Evaluation of a New Merged Sea-Ice Concentration Dataset at 1 km Resolution from Thermal Infrared and Passive Microwave Satellite Data in the Arctic},
  year      = {2020},
  month     = {sep},
  number    = {19},
  pages     = {3183},
  volume    = {12},
  comment   = {Paper presenting a merged SIC rs product on a 1km grid},
  doi       = {10.3390/rs12193183},
  file      = {:Ludwig2020.pdf:PDF},
  publisher = {{MDPI} {AG}},
}

@Misc{tensorflow2015-whitepaper,
  author = {Mart\'{i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
  note   = {Software available from tensorflow.org},
  title  = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
  year   = {2015},
  url    = {https://www.tensorflow.org/},
}

@Article{Cavalieri2012,
  author    = {D. J. Cavalieri and C. L. Parkinson},
  journal   = {The Cryosphere},
  title     = {Arctic sea ice variability and trends, 1979{\textendash}2010},
  year      = {2012},
  month     = {aug},
  number    = {4},
  pages     = {881--889},
  volume    = {6},
  doi       = {10.5194/tc-6-881-2012},
  publisher = {Copernicus {GmbH}},
}

@Article{Comiso2017,
  author    = {Josefino C. Comiso and Walter N. Meier and Robert Gersten},
  journal   = {Journal of Geophysical Research: Oceans},
  title     = {Variability and trends in the $\less$scp$\greater$A$\less$/scp$\greater$ rctic $\less$scp$\greater$S$\less$/scp$\greater$ ea ice cover: Results from different techniques},
  year      = {2017},
  month     = {aug},
  number    = {8},
  pages     = {6883--6900},
  volume    = {122},
  doi       = {10.1002/2017jc012768},
  publisher = {American Geophysical Union ({AGU})},
}

@Article{Notz2020,
  author    = {Dirk Notz and SIMIP Community},
  journal   = {Geophysical Research Letters},
  title     = {Arctic Sea Ice in {CMIP}6},
  year      = {2020},
  month     = {may},
  number    = {10},
  volume    = {47},
  doi       = {10.1029/2019gl086749},
  publisher = {American Geophysical Union ({AGU})},
}

@Article{Eguiluz2016,
  author    = {Victor M. Egu{\'{\i}}luz and Juan Fern{\'{a}}ndez-Gracia and Xabier Irigoien and Carlos M. Duarte},
  journal   = {Scientific Reports},
  title     = {A quantitative assessment of Arctic shipping in 2010{\textendash}2014},
  year      = {2016},
  month     = {aug},
  number    = {1},
  volume    = {6},
  doi       = {10.1038/srep30682},
  publisher = {Springer Science and Business Media {LLC}},
}

@Misc{nextsimdata2020,
  author    = {{European Union-Copernicus Marine Service}},
  title     = {Arctic Ocean Sea Ice Analysis and Forecast},
  year      = {2020},
  doi       = {10.48670/MOI-00004},
  keywords  = {oceanography},
  language  = {en},
  publisher = {Mercator Ocean International},
}

@Article{Williams2021,
  author    = {Timothy Williams and Anton Korosov and Pierre Rampal and Einar {\'{O}}lason},
  journal   = {The Cryosphere},
  title     = {Presentation and evaluation of the Arctic sea ice forecasting system {neXtSIM}-F},
  year      = {2021},
  month     = {jul},
  number    = {7},
  pages     = {3207--3227},
  volume    = {15},
  comment   = {Paper presenting the neXtSIM physical sea ice model},
  doi       = {10.5194/tc-15-3207-2021},
  file      = {:Williams2021.pdf:PDF},
  publisher = {Copernicus {GmbH}},
}

@Article{Liu2021,
  author    = {Yang Liu and Laurens Bogaardt and Jisk Attema and Wilco Hazeleger},
  journal   = {Monthly Weather Review},
  title     = {Extended Range Arctic Sea Ice Forecast with Convolutional Long-Short Term Memory Networks},
  year      = {2021},
  month     = {mar},
  doi       = {10.1175/mwr-d-20-0113.1},
  file      = {:Liu2021.pdf:PDF},
  publisher = {American Meteorological Society},
}

@Article{rs14225837,
  author         = {Grigoryev, Timofey and Verezemskaya, Polina and Krinitskiy, Mikhail and Anikin, Nikita and Gavrikov, Alexander and Trofimov, Ilya and Balabin, Nikita and Shpilman, Aleksei and Eremchenko, Andrei and Gulev, Sergey and Burnaev, Evgeny and Vanovskiy, Vladimir},
  journal        = {Remote Sensing},
  title          = {Data-Driven Short-Term Daily Operational Sea Ice Regional Forecasting},
  year           = {2022},
  issn           = {2072-4292},
  number         = {22},
  volume         = {14},
  abstract       = {Global warming has made the Arctic increasingly available for marine operations and created a demand for reliable operational sea ice forecasts to increase safety. Because ocean-ice numerical models are highly computationally intensive, relatively lightweight ML-based methods may be more efficient for sea ice forecasting. Many studies have exploited different deep learning models alongside classical approaches for predicting sea ice concentration in the Arctic. However, only a few focus on daily operational forecasts and consider the real-time availability of data needed for marine operations. In this article, we aim to close this gap and investigate the performance of the U-Net model trained in two regimes for predicting sea ice for up to the next 10 days. We show that this deep learning model can outperform simple baselines by a significant margin, and we can improve the model&rsquo;s quality by using additional weather data and training on multiple regions to ensure its generalization abilities. As a practical outcome, we build a fast and flexible tool that produces operational sea ice forecasts in the Barents Sea, the Labrador Sea, and the Laptev Sea regions.},
  article-number = {5837},
  doi            = {10.3390/rs14225837},
  file           = {:Grigoryev2022.pdf:PDF},
  url            = {https://www.mdpi.com/2072-4292/14/22/5837},
}

@Article{Serreze2019,
  author   = {Serreze, Mark C. and Meier, Walter N.},
  journal  = {Annals of the New York Academy of Sciences},
  title    = {The Arctic's sea ice cover: trends, variability, predictability, and comparisons to the Antarctic},
  year     = {2019},
  number   = {1},
  pages    = {36-53},
  volume   = {1436},
  abstract = {Abstract As assessed over the period of satellite observations, October 1978 to present, there are downward linear trends in Arctic sea ice extent for all months, largest at the end of the melt season in September. The ice cover is also thinning. Downward trends in extent and thickness have been accompanied by pronounced interannual and multiyear variability, forced by both the atmosphere and ocean. As the ice thins, its response to atmospheric and oceanic forcing may be changing. In support of a busier Arctic, there is a growing need to predict ice conditions on a variety of time and space scales. A major challenge to providing seasonal scale predictions is the 7–10 days limit of numerical weather prediction. While a seasonally ice-free Arctic Ocean is likely well within this century, there is much uncertainty in the timing. This reflects differences in climate model structure, the unknown evolution of anthropogenic forcing, and natural climate variability. In sharp contrast to the Arctic, Antarctic sea ice extent, while highly variable, has increased slightly over the period of satellite observations. The reasons for this different behavior remain to be resolved, but responses to changing atmospheric circulation patterns appear to play a strong role.},
  doi      = {https://doi.org/10.1111/nyas.13856},
  file     = {:Serreze2018.pdf:PDF},
  keywords = {Arctic, Antarctic, sea ice, trends, variability, predictability},
}

@Article{Johnson2019,
  author  = {Johnson, S. J. and Stockdale, T. N. and Ferranti, L. and Balmaseda, M. A. and Molteni, F. and Magnusson, L. and Tietsche, S. and Decremer, D. and Weisheimer, A. and Balsamo, G. and Keeley, S. P. E. and Mogensen, K. and Zuo, H. and Monge-Sanz, B. M.},
  journal = {Geoscientific Model Development},
  title   = {SEAS5: the new ECMWF seasonal forecast system},
  year    = {2019},
  number  = {3},
  pages   = {1087--1117},
  volume  = {12},
  doi     = {10.5194/gmd-12-1087-2019},
  url     = {https://gmd.copernicus.org/articles/12/1087/2019/},
}

@Article{Lavergne2019,
  author  = {Lavergne, T. and S{\o}rensen, A. M. and Kern, S. and Tonboe, R. and Notz, D. and Aaboe, S. and Bell, L. and Dybkj{\ae}r, G. and Eastwood, S. and Gabarro, C. and Heygster, G. and Killie, M. A. and Brandt Kreiner, M. and Lavelle, J. and Saldo, R. and Sandven, S. and Pedersen, L. T.},
  journal = {The Cryosphere},
  title   = {Version 2 of the EUMETSAT OSI SAF and ESA CCI sea-ice concentration climate data records},
  year    = {2019},
  number  = {1},
  pages   = {49--78},
  volume  = {13},
  doi     = {10.5194/tc-13-49-2019},
  url     = {https://tc.copernicus.org/articles/13/49/2019/},
}

@Article{Hersbach2020,
  author   = {Hersbach, Hans and Bell, Bill and Berrisford, Paul and Hirahara, Shoji and Horányi, András and Muñoz-Sabater, Joaquín and Nicolas, Julien and Peubey, Carole and Radu, Raluca and Schepers, Dinand and Simmons, Adrian and Soci, Cornel and Abdalla, Saleh and Abellan, Xavier and Balsamo, Gianpaolo and Bechtold, Peter and Biavati, Gionata and Bidlot, Jean and Bonavita, Massimo and De Chiara, Giovanna and Dahlgren, Per and Dee, Dick and Diamantakis, Michail and Dragani, Rossana and Flemming, Johannes and Forbes, Richard and Fuentes, Manuel and Geer, Alan and Haimberger, Leo and Healy, Sean and Hogan, Robin J. and Hólm, Elías and Janisková, Marta and Keeley, Sarah and Laloyaux, Patrick and Lopez, Philippe and Lupu, Cristina and Radnoti, Gabor and de Rosnay, Patricia and Rozum, Iryna and Vamborg, Freja and Villaume, Sebastien and Thépaut, Jean-Noël},
  journal  = {Quarterly Journal of the Royal Meteorological Society},
  title    = {The ERA5 global reanalysis},
  year     = {2020},
  number   = {730},
  pages    = {1999-2049},
  volume   = {146},
  abstract = {Abstract Within the Copernicus Climate Change Service (C3S), ECMWF is producing the ERA5 reanalysis which, once completed, will embody a detailed record of the global atmosphere, land surface and ocean waves from 1950 onwards. This new reanalysis replaces the ERA-Interim reanalysis (spanning 1979 onwards) which was started in 2006. ERA5 is based on the Integrated Forecasting System (IFS) Cy41r2 which was operational in 2016. ERA5 thus benefits from a decade of developments in model physics, core dynamics and data assimilation. In addition to a significantly enhanced horizontal resolution of 31 km, compared to 80 km for ERA-Interim, ERA5 has hourly output throughout, and an uncertainty estimate from an ensemble (3-hourly at half the horizontal resolution). This paper describes the general set-up of ERA5, as well as a basic evaluation of characteristics and performance, with a focus on the dataset from 1979 onwards which is currently publicly available. Re-forecasts from ERA5 analyses show a gain of up to one day in skill with respect to ERA-Interim. Comparison with radiosonde and PILOT data prior to assimilation shows an improved fit for temperature, wind and humidity in the troposphere, but not the stratosphere. A comparison with independent buoy data shows a much improved fit for ocean wave height. The uncertainty estimate reflects the evolution of the observing systems used in ERA5. The enhanced temporal and spatial resolution allows for a detailed evolution of weather systems. For precipitation, global-mean correlation with monthly-mean GPCP data is increased from 67\% to 77\%. In general, low-frequency variability is found to be well represented and from 10 hPa downwards general patterns of anomalies in temperature match those from the ERA-Interim, MERRA-2 and JRA-55 reanalyses.},
  doi      = {https://doi.org/10.1002/qj.3803},
  eprint   = {https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3803},
  keywords = {climate reanalysis, Copernicus Climate Change Service, data assimilation, ERA5, historical observations},
  url      = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.3803},
}

@Article{Dee2011,
  author   = {Dee, D. P. and Uppala, S. M. and Simmons, A. J. and Berrisford, P. and Poli, P. and Kobayashi, S. and Andrae, U. and Balmaseda, M. A. and Balsamo, G. and Bauer, P. and Bechtold, P. and Beljaars, A. C. M. and van de Berg, L. and Bidlot, J. and Bormann, N. and Delsol, C. and Dragani, R. and Fuentes, M. and Geer, A. J. and Haimberger, L. and Healy, S. B. and Hersbach, H. and Hólm, E. V. and Isaksen, L. and Kållberg, P. and Köhler, M. and Matricardi, M. and McNally, A. P. and Monge-Sanz, B. M. and Morcrette, J.-J. and Park, B.-K. and Peubey, C. and de Rosnay, P. and Tavolato, C. and Thépaut, J.-N. and Vitart, F.},
  journal  = {Quarterly Journal of the Royal Meteorological Society},
  title    = {The ERA-Interim reanalysis: configuration and performance of the data assimilation system},
  year     = {2011},
  number   = {656},
  pages    = {553-597},
  volume   = {137},
  abstract = {Abstract ERA-Interim is the latest global atmospheric reanalysis produced by the European Centre for Medium-Range Weather Forecasts (ECMWF). The ERA-Interim project was conducted in part to prepare for a new atmospheric reanalysis to replace ERA-40, which will extend back to the early part of the twentieth century. This article describes the forecast model, data assimilation method, and input datasets used to produce ERA-Interim, and discusses the performance of the system. Special emphasis is placed on various difficulties encountered in the production of ERA-40, including the representation of the hydrological cycle, the quality of the stratospheric circulation, and the consistency in time of the reanalysed fields. We provide evidence for substantial improvements in each of these aspects. We also identify areas where further work is needed and describe opportunities and objectives for future reanalysis projects at ECMWF. Copyright © 2011 Royal Meteorological Society},
  doi      = {https://doi.org/10.1002/qj.828},
  eprint   = {https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.828},
  keywords = {ERA-40, 4D-Var, hydrological cycle, stratospheric circulation, observations, forecast model},
  url      = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.828},
}

@Article{Balmaseda2013,
  author   = {Balmaseda, Magdalena Alonso and Mogensen, Kristian and Weaver, Anthony T.},
  journal  = {Quarterly Journal of the Royal Meteorological Society},
  title    = {Evaluation of the ECMWF ocean reanalysis system ORAS4},
  year     = {2013},
  number   = {674},
  pages    = {1132-1161},
  volume   = {139},
  abstract = {Abstract A new operational ocean reanalysis system (ORAS4) has been implemented at ECMWF. It spans the period 1958 to the present. This article describes its main components and evaluates its quality. The adequacy of ORAS4 for the initialization of seasonal forecasts is discussed, along with the robustness of some prominent climate signals. ORAS4 has been evaluated using different metrics, including comparison with observed ocean currents, RAPID-derived transports, sea-level gauges, and GRACE-derived bottom pressure. Compared to a control ocean model simulation, ORAS4 improves the fit to observations, the interannual variability, and seasonal forecast skill. Some problems have been identified, such as the underestimation of meridional overturning at 26°N, the magnitude of which is shown to be sensitive to the treatment of the coastal observations. ORAS4 shows a clear and robust shallowing trend of the Pacific Equatorial thermocline. It also shows a clear and robust nonlinear trend in the 0–700 m ocean heat content, consistent with other observational estimates. Some aspects of these climate signals are sensitive to the choice of sea-surface temperature product and the specification of the observation-error variances. The global sea-level trend is consistent with the altimeter estimate, but the partition into volume and mass variations is more debatable, as inferred by discrepancies in the trend between ORAS4- and GRACE-derived bottom pressure.},
  doi      = {https://doi.org/10.1002/qj.2063},
  eprint   = {https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.2063},
  keywords = {ocean reanalysis, climate variability, validation, quality metric, initialization},
  url      = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.2063},
}

@Article{Chin2017,
  author    = {Toshio Michael Chin and Jorge Vazquez-Cuervo and Edward M. Armstrong},
  journal   = {Remote Sensing of Environment},
  title     = {A multi-scale high-resolution analysis of global sea surface temperature},
  year      = {2017},
  month     = {oct},
  pages     = {154--169},
  volume    = {200},
  doi       = {10.1016/j.rse.2017.07.029},
  publisher = {Elsevier {BV}},
}

@Misc{Kristensen2017,
  author    = {Kristensen, Nils M and {JensBDebernard} and {SebastianMaartensson} and {Keguang Wang} and Hedstrom, Kate},
  title     = {Metno/Metroms: Version 0.3 - Before Merge},
  year      = {2017},
  copyright = {Open Access},
  doi       = {10.5281/ZENODO.1046114},
  publisher = {Zenodo},
}

@InProceedings{NVIDIA,
  author = {NVIDIA},
  title  = {NVIDIA A100 Tensor Core GPU Architecture UNPRECEDENTED ACCELERATION AT EVERY SCALE},
  file   = {:/home/arefk/uio/MScThesis_AreKvanum2022_SeaIceML/thesis/bib/nvidia-ampere-architecture-whitepaper.pdf:PDF},
}

@Article{Roehrs2022,
  author   = {Johannes Röhrs and Yvonne Gusdal and Edel Rikardsen and Marina Duran Moro and Jostein Brændshøi and Nils Melsom Kristensen and Sindre Fritzner and Keguang Wang and Ann Kristin Sperrevik and Martina Idžanović and ThomasLavergne and Jens Debernard and Kai H. Christensen},
  title    = {"in prep for GMD" An operational data-assimilative coupled ocean and sea ice ensembleprediction model for the Barents Sea and Svalbard},
  year     = {2022},
  pages    = {20},
  abstract = {An operational ocean and sea ice forecast model, Barents-2.5 , is implemented at MET Norway for short-term forecasting of the ocean’s state at the coast off Northern Norway, the Barents Sea, and waters around Svalbard. Primary forecast parameters are the extent of the ice cover, sea surface temperature (SST), and ocean currents. The model is also an
substantial input for drift modeling of pollutants, ice berg, and in search-and-rescue pertinent applications in the Arctic domain. Barents-2.5 has recently been upgraded to include an Ensemble Prediction System with 24 daily realizations of the model state. Sea ice cover, SST and in-situ hydrography are constrained through a Ensemble-Kalman filter (EnKF) data assimilation scheme executed in daily forecast cycles with lead time up to 66 hours. While the ocean circulation is not directly constrained
by assimilation of ocean currents, the model ensemble represents the given uncertainty in the short-term current field by retaining the current state for each member throughout forecast cycles. We present here a model validation in terms of sea ice concentration, SST and in-situ hydrography, the performance of the ensemble to represent the models uncertainty, and the performance of the EnKF to constrain the model state. Finally, a discussion of forecast skill for selected variables is provided.},
  comment  = {"GMD" = Geoscientific Model Development?},
  file     = {:Roehrs2022.pdf:PDF},
}

@TechReport{Hunke2015,
  author      = {Elizabeth C. Hunke and William H. Lipscomb and Adrian K. Turner and Nicole Jeffery and Scott Elliott},
  institution = {Los Alamos National Laboratory},
  title       = {CICE: the Los Alamos Sea Ice Model Documentation and Software User’s Manual Version 5.1 LA-CC-06-012},
  year        = {2015},
  address     = {Los Alamos NM 87545},
  month       = jul,
  type        = {techreport},
}

@Article{Olason2022,
  author    = {Einar {\'{O}}lason and Guillaume Boutin and Anton Korosov and Pierre Rampal and Timothy Williams and Madlen Kimmritz and V{\'{e}}ronique Dansereau and Abdoulaye Samak{\'{e}}},
  journal   = {Journal of Advances in Modeling Earth Systems},
  title     = {A New Brittle Rheology and Numerical Framework for Large-Scale Sea-Ice Models},
  year      = {2022},
  month     = {aug},
  number    = {8},
  volume    = {14},
  doi       = {10.1029/2021ms002685},
  publisher = {American Geophysical Union ({AGU})},
}

@Article{Dansereau2016,
  author    = {V{\'{e}}ronique Dansereau and J{\'{e}}r{\^{o}}me Weiss and Pierre Saramito and Philippe Lattes},
  journal   = {The Cryosphere},
  title     = {A Maxwell elasto-brittle rheology for sea ice modelling},
  year      = {2016},
  month     = {jul},
  number    = {3},
  pages     = {1339--1359},
  volume    = {10},
  doi       = {10.5194/tc-10-1339-2016},
  publisher = {Copernicus {GmbH}},
}

@Article{Hibler1979,
  author    = {W. D. Hibler},
  journal   = {Journal of Physical Oceanography},
  title     = {A Dynamic Thermodynamic Sea Ice Model},
  year      = {1979},
  month     = {jul},
  number    = {4},
  pages     = {815--846},
  volume    = {9},
  doi       = {10.1175/1520-0485(1979)009<0815:adtsim>2.0.co;2},
  publisher = {American Meteorological Society},
}

@Article{Hunke1997,
  author    = {E. C. Hunke and J. K. Dukowicz},
  journal   = {Journal of Physical Oceanography},
  title     = {An Elastic{\textendash}Viscous{\textendash}Plastic Model for Sea Ice Dynamics},
  year      = {1997},
  month     = {sep},
  number    = {9},
  pages     = {1849--1867},
  volume    = {27},
  doi       = {10.1175/1520-0485(1997)027<1849:aevpmf>2.0.co;2},
  publisher = {American Meteorological Society},
}

@Article{Sakov2008,
  author    = {Pavel Sakov and Peter R. Oke},
  journal   = {Tellus A: Dynamic Meteorology and Oceanography},
  title     = {A deterministic formulation of the ensemble Kalman filter: an alternative to ensemble square root filters},
  year      = {2008},
  month     = {jan},
  number    = {2},
  pages     = {361},
  volume    = {60},
  doi       = {10.1111/j.1600-0870.2007.00299.x},
  publisher = {Stockholm University Press},
}

@Article{Kern2019,
  author    = {Stefan Kern and Thomas Lavergne and Dirk Notz and Leif Toudal Pedersen and Rasmus Tage Tonboe and Roberto Saldo and Atle MacDonald S{\o}rensen},
  journal   = {The Cryosphere},
  title     = {Satellite passive microwave sea-ice concentration data set intercomparison: closed ice and ship-based observations},
  year      = {2019},
  month     = {dec},
  number    = {12},
  pages     = {3261--3307},
  volume    = {13},
  doi       = {10.5194/tc-13-3261-2019},
  file      = {:Kern2019.pdf:PDF},
  publisher = {Copernicus {GmbH}},
}

@Article{Wagner2020,
  author    = {Penelope Mae Wagner and Nick Hughes and Pascale Bourbonnais and Julienne Stroeve and Lasse Rabenstein and Uma Bhatt and Joe Little and Helen Wiggins and Andrew Fleming},
  journal   = {Polar Geography},
  title     = {Sea-ice information and forecast needs for industry maritime stakeholders},
  year      = {2020},
  month     = {jun},
  number    = {2-3},
  pages     = {160--187},
  volume    = {43},
  doi       = {10.1080/1088937x.2020.1766592},
  file      = {:Wagner2020.pdf:PDF},
  publisher = {Informa {UK} Limited},
}

@Article{Palerme2019,
  author    = {Cyril Palerme and Malte Müller and Arne Melsom},
  journal   = {Geophysical Research Letters},
  title     = {An Intercomparison of Verification Scores for Evaluating the Sea Ice Edge Position in Seasonal Forecasts},
  year      = {2019},
  month     = {may},
  number    = {9},
  pages     = {4757--4763},
  volume    = {46},
  comment   = {Section 4 Paragraph 1"
For example, a high
sensitivity to isolated ice patches can be suitable for evaluating the forecast ability to reproduce coastal sea
ice, while this can be inadequate for comparing the general agreement between the forecast and observed
ice edge positions.
"

This is an interesting remark as to why I should avoid computing the MHD for my dataset, however it could be interesting to inspect how the metric performs for high resolution data, as isolated ice patches could be spatially resolved by the ice charts.},
  doi       = {10.1029/2019gl082482},
  file      = {Sea Ice Edge position verification for seasonal forecasting:Palerme2019.pdf:PDF},
  publisher = {American Geophysical Union ({AGU})},
}

@TechReport{Veland2021,
  author      = {S Veland and P Wagner and D Bailey and A Everett and M Goldstein and R Hermann and T Hjort-Larsen and G Hovelsrud and N Hughes and A Kjøl and X Li and A Lynch and M Müller and J Olsen and C Palerme and J L Pedersen and Ø Rinaldo and S Stephenson and T Storelvmo},
  institution = {Svalbard Strategic Grant, Svalbard Science Forum},
  title       = {Knowledge needs in sea ice forecasting for navigation in Svalbard and the High Arctic},
  year        = {2021},
  number      = {NF-rapport 4/2021},
}

@Comment{jabref-meta: databaseType:bibtex;}
